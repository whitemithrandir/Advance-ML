Eğer bir ikili sınıflandırma problemi üzerinde çalışılıyorsa, çıktı katmanında sigmoid kullanılır.

Örneğin, yarının hisse senedi fiyatının bugünün hisse senedi fiyatına kıyasla nasıl değişeceğini tahmin etmeye çalışıyorsanız.
Pekala, yukarı veya aşağı gidebilir ve bu durumda y pozitif veya negatif olabilen bir sayı olur ve bu durumda
doğrusal aktivasyon fonksiyonunu kullanmanızı tavsiye ederim.

örneğin bir evin fiyatını tahmin ediyorsanız, bu asla negatif olamaz, o zaman en doğal seçim ReLU aktivasyon fonksiyonu
olacaktır çünkü burada gördüğünüz gibi, bu etkinleştirme işlevi yalnızca sıfır veya pozitif değerler olmak üzere negatif
olmayan değerleri alır

Gradyan iniş, makine öğreniminde yaygın olarak kullanılan bir optimizasyon algoritmasıdır ve doğrusal regresyon ve
lojistik regresyon
ve sinir ağlarının erken uygulamaları gibi birçok algoritmanın temeli olmuştur.

Adam optimizasyon algoritması tipik olarak eğimli inişten çok daha hızlı çalışır ve uygulayıcıların sinir ağlarını nasıl
eğittiği
konusunda fiili bir standart halindedir. Hangi öğrenme algoritmasının kullanılacağına, sinir ağınızı eğitmek için hangi
optimizasyon
algoritmasının kullanılacağına karar vermeye çalışılıyorsa. Güvenli bir seçim sadece Adam optimizasyon algoritmasını
kullanmak olacaktır.

##Evaluating a model
makine öğrenimi sistemlerinin nasıl oluşturulacağına dair bazı tavsiyeler;
ekiplerin kelimenin tam anlamıyla aylarca daha fazla eğitim örneği toplayarak, daha fazla eğitim verisinin yardımcı
olacağını
düşünerek harcadıklarını gördüm, ancak bazen çok yardımcı olduğu ve bazen de yaramadığı ortaya çıktı
Bir makine öğrenimi algoritması oluşturmada etkili olmanın anahtarı, zamanınızı nereye harcayacağınız konusunda iyi
seçimler yapmaktır.
Bilgisayar için genellikle yararlı olan niceliklerden biri ve eğitim hatası, albümünüzün eğitim setinde ne kadar
iyi çalıştığının
bir ölçüsüdür.

## Diagnosing bias and variance
Makine öğrenimi sistemi oluşturma sürecinin anahtarı, performansını artırmak için bir sonraki adımda ne yapılacağına
nasıl karar
verileceğidir. Bir öğrenme algoritmasının önyargı ve varyansına bakmanın, bir sonraki denemeniz konusunda size çok iyi
rehberlik sağlar.
algoritmanızın yüksek önyargı veya yüksek varyansa sahip olup olmadığını teşhis etmenin veya bulmanın sistematik bir yolu,
algoritmanızın eğitim setindeki ve çapraz doğrulama setindeki performansına bakmak olacaktır
Yüksek varyansın temel göstergesi, J_cv'nin J treninden çok daha büyük olması durumunda olacak olsa da,
matematikte işaretten iki kat daha büyüktür, bu nedenle bu daha büyüktür ve bu çok daha büyük anlamına gelir.
Çizimin bu en sağdaki kısmı, J_cv'nin J treninden çok daha büyük olduğu yerdir. Genellikle J katarı oldukça düşük olacaktır,
ancak temel gösterge J_cv'nin J katarından çok daha büyük olup olmadığıdır

## Regularization and bias/variance
algoritmanız için düzenleme parametresinin iyi bir Lambda değerini seçmek istediğinizde yardımcı olacaktır
Burada Lambda değeri, eğitim verilerini iyi uydurmaya karşı w parametrelerini küçük tutmaktan ne kadar ödün verdiğinizi
kontrol eden düzenleme parametresidir
yüksek lambda yüksek bias demektir. Lambda 0 olursa overfit olur. İdeal bir aralıkta seçmek gerekir
Normalleştirme parametresi için kullanılacak iyi bir Lambda değerinin ne olduğuna karar vermeye çalışıyorsanız, çapraz 
doğrulama size bunu yapmanın bir yolunu da sunar
Algoritmanın en iyi performansı göstermesine neden olan bazı ara Lambda değerleri olacaktır. Çapraz doğrulamanın yaptığı şey,
Lambda'nın birçok farklı değerini denemektir
Lambda düzenleme parametresinin seçimi, algoritmanızın önyargısını ve varyansını ve genel performansını etkiler ve ayrıca
Lambda düzenleme parametresi için iyi bir seçim yapmak üzere çapraz doğrulama kullanılabilir.

## Learning curves
Eğitim seti boyutu büyüdükçe, eğitim seti hatası aslında artar.
bir öğrenme algoritmasının yüksek önyargıya sahip olması durumunda, daha fazla eğitim verisi elde etmenin tek başına
o kadar fazla umut vermeyeceği sonucuna varıyor, belki biraz şaşırtıcı. Daha fazla veriye sahip olmanın iyi olduğunu
düşünmeye alıştığımızı biliyorum, ancak algoritmanız yüksek önyargıya sahipse, yaptığınız tek şey daha fazla eğitim
verisi eklemekse, bu tek başına hatayı azaltmanıza asla izin vermez. bu kadar değerlendir. Gerçekten bu nedenle,
bu şekle ne kadar çok örnek eklerseniz ekleyin, düz doğrusal uydurma o kadar iyi olmayacak. Bu nedenle, daha fazla
eğitim verisi toplamak için çok çaba harcamadan önce, öğrenme algoritmanızın yüksek önyargıya sahip olup olmadığını
kontrol etmeye değer, çünkü varsa, muhtemelen daha fazla eğitim verisi eklemekten başka şeyler yapmanız gerekir.
Varyansınız yüksek olduğunda, eğitim kümesi boyutunu artırmak çok yardımcı olabilir ve özellikle, bu eğrileri sağa doğru
tahmin edebilirsek, M katını artırabilirsek, eğitim hatası artmaya devam eder, ancak sonra çapraz- doğrulama hatası umarım
aşağı inecek ve J trenine yaklaşacaktır. Dolayısıyla bu senaryoda, çapraz doğrulama hatasını azaltmak ve algoritmanızın
daha iyi ve daha iyi performans göstermesini sağlamak için yalnızca eğitim seti boyutunu artırarak mümkün olabilir ve bu,
yüksek önyargı durumundan farklıdır, burada yaptığınız tek şey Algoritma performansınızı çok fazla öğrenmenize yardımcı
olmayacak daha fazla eğitim verisi elde etmektir. Özetlemek gerekirse, bir öğrenme algoritması yüksek varyanstan muzdaripse,
o zaman daha fazla eğitim verisi elde etmek gerçekten yardımcı olacaktır.

## Deciding what to try next revisited
Öğrenme algoritmanızın yüksek önyargılı mı yoksa yüksek varyanslı mı olduğunu anlamaya çalışabilirsiniz.
Bu, bir öğrenme algoritması eğitirken rutin olarak yaptığım prosedürdür, algoritmamın yüksek önyargı veya
yüksek varyansa sahip olup olmadığına karar vermeye çalışmak için eğitim hatasına ve çapraz doğrulama hatasına daha sık bakarım.

## Deciding what to try next revisited
algoritmanız yüksek yanlılığa sahipse, o zaman yaptığımız tek şey daha fazla eğitim verisi almaksa, bu muhtemelen tek başına
o kadar da yardımcı olmaz. Ancak bunun aksine, algoritmanız yüksek varyansa sahipse, diyelim ki çok küçük bir eğitim setine
fazla uyuyorsa, o zaman daha fazla eğitim örneği almak çok yardımcı olacaktır
öğrenme algoritmanızın çok fazla özelliği varsa, algoritmanıza çok karmaşık modellere uyması için çok fazla esneklik sağlar.
Bu biraz x, x squared, x cubed, x^4, x^5, vb. gibi. Bunlardan sadece birkaçını ortadan kaldırsaydınız, modeliniz
çok karmaşık olmayacak ve bu kadar yüksek varyansa sahip olmayacaktı.
Lambdayı arttırmak overfit(high variance) problemini çözer.
Lambdayı azaltmak bias problemini çözer.
algoritmanızın yüksek varyansa sahip olduğunu tespit ederseniz, bunu düzeltmenin iki ana yolu;
ne daha fazla eğitim verisi alın ne de modelinizi basitleştirin. Modeli basitleştirerek demek istediğim,
ya daha küçük bir dizi özellik elde edin ya da Lambda düzenleme parametresini artırın. Algoritmanızın çok karmaşık,
çok hareketli eğrilere uyma esnekliği daha azdır. Tersine, algoritmanız yüksek önyargıya sahipse,
bu eğitim setinde bile iyi gitmiyor demektir. Durum buysa, ana düzeltmeler, modelinizi daha güçlü hale getirmek
veya onlara daha karmaşık veya daha fazla işleve uymaları için daha fazla esneklik kazandırmaktır.
Bunu yapmanın bazı yolları, ona ek özellikler vermek veya bu polinom özelliklerini eklemek veya
Lambda düzenleme parametresini azaltmaktır.
eğitim seti boyutunu küçülterek yüksek önyargıyı düzeltmeniz gerekip gerekmediğini merak ediyorsanız,
bu aslında yardımcı olmuyor. Eğitim seti boyutunu küçültürseniz, eğitim setine daha iyi uyarsınız, ancak bu,
çapraz doğrulama hatanızı ve öğrenme algoritmanızın performansını kötüleştirme eğilimindedir, bu nedenle,
yalnızca yüksek bir değeri düzeltmeye çalışmak için eğitim örneklerini rastgele atmayın

## Bias/variance and neural networks
eğer sinir ağınızı yeterince genişletirseniz, neredeyse her zaman eğitim setinize iyi uyum sağlayabilirsiniz.
Eğitim setiniz çok büyük olmadığı sürece. Ve bunun anlamı, ikisi arasında gerçekten değiş tokuş yapmaya gerek kalmadan
önyargıyı azaltmaya veya varyansı gerektiği gibi azaltmaya çalışmak için bize yeni bir reçete veriyor.
önyargıyı azaltmanın bir yolu, sadece daha büyük bir sinir ağı kullanmaktır ve daha büyük sinir ağı ile,
katman başına daha fazla gizli katman veya daha fazla gizli birim demek istiyorum. Ve daha sonra bu döngüden geçmeye devam edebilir
ve sinir ağınızı eğitim setinde başarılı olana kadar daha da büyütebilirsiniz
Eğitim setine düştükten sonra, bu sorunun cevabı evet. Daha sonra, trans doğrulama setinde iyi sonuç vermediğini sorarsınız.
Tekrar eğittikten sonra;
algoritmanın yüksek varyansa sahip olduğu sonucuna varabilirsiniz çünkü çapraz doğrulama setinde set eğitmek istemiyor.
Dolayısıyla, Jcv ve Jtrain'deki bu büyük boşluk, muhtemelen yüksek bir varyans sorununuz olduğunu gösterir ve
yüksek bir varyans sorununuz varsa, bunu düzeltmenin bir yolu daha fazla veri elde etmektir.
Daha fazla veri almak ve geri dönüp modeli yeniden eğitmek ve iki kez kontrol etmek

## Error analysis
Öğrenme algoritması performansınızı iyileştirmek için bir sonraki denemeyi seçmek için tanılama çalıştırmanıza yardımcı olacak
en önemli yollar açısından, yanlılık ve varyansın muhtemelen en önemli fikir olduğunu ve hata analizinin muhtemelen listemde ikinci
olacağını söyleyebilirim.
Örneğin, yanlış sınıflandırılmış spam e-postalarının birçoğunun ilaç satışı olduğunu, ilaç veya ilaç satmaya çalıştığını
fark ederseniz, aslında bu örnekleri inceleyeceğim ve bu sınıflandırmadaki kaç e-postanın farmasötik spam olduğunu elle
karşılayacağım ve orada olduğunu söyleyeceğim.
istenmeyen e-postaları bulmak için algoritmalar oluşturmak için çok zaman harcadım, ancak çok sonra net etkinin aslında
oldukça küçük olduğunu fark ettim. Bu, kasıtlı yazım yanlışlarını bulmaya çalışmak için çok zaman harcamadan önce daha dikkatli
hata analizi yapmayı dilediğim bir örnek
Bu analizden sonra, birçok hatanın farmasötik spam e-postaları olduğunu fark ederseniz, bu size daha sonra yapılacak şeyler
için bazı fikirler veya ilham verebilir. Örneğin, her şeyden daha fazla veri değil de daha fazla veri toplamaya karar
verebilirsiniz, ancak öğrenme algoritmasının bu farmasötik istenmeyen postaları tanımada daha iyi bir iş çıkarabilmesi için
farmasötik spam e-postalarına ilişkin daha fazla veri bulmaya çalışabilirsiniz. Veya satmaya çalıştığınız standartların belirli
ilaç adlarını veya farmasötik ürünlerin belirli adlarını söylemekle ilgili bazı yeni özellikler bulmaya karar verebilirsiniz
öğrenme algoritmanızın onları tanıma konusunda daha iyi bir iş çıkarmasına yardımcı olmak için özellikle kimlik avı e-postalarından
daha fazla veri almaya karar verebilirsiniz.
Genel olarak, hem sapma varyansı teşhisini hem de bu tür hata analizini gerçekleştirmenin taramaya veya modelde hangi
değişikliklerin bir sonraki denemede daha umut verici olduğuna karar vermeye gerçekten yardımcı olduğunu buldum.
Şimdi hata analizinin bir sınırlaması, insanların iyi olduğu problemler için bunu yapmanın çok daha kolay olmasıdır.
Özetle hata analizinde ayıklamak yerine spam olduğunu bildiğin verilerle eğitmek zamandan daha çok kazandırır.

## Adding data
Makine öğrenimi algoritmalarını eğitirken, neredeyse her zaman daha fazla veriye sahip olmayı dilemişiz gibi geliyor.
Ve bu yüzden bazen her şey hakkında daha fazla veri elde etmemize izin vermek cazip geliyor. Ancak her türden daha fazla veri
elde etmeye çalışmak yavaş ve pahalı olabilir. Bunun yerine, veri eklemenin alternatif bir yolu, analizin yardımcı olabileceğini
belirttiği türlerden daha fazla veri eklemeye odaklanmak olabilir. Önceki slaytta, hata analizinin ilaç spam'inin büyük bir
sorun olduğunu gözden geçirip geçirmediğini gördük, o zaman güneş altında her şeyi daha fazla veri almak için değil, daha fazla
farmasötik spam örneği almaya odaklanmak için daha hedefli bir çaba göstermeye karar verebilirsiniz. daha mütevazı bir maliyet bu
çok fazla etiketlenmemiş e-posta veriniz varsa, etrafta dolaşan e-postalar varsa ve henüz kimsenin spam veya spam olmayan
olarak etiketleme zahmetine girmediğini varsayalım. etiketlenmemiş veriler aracılığıyla ve özellikle ilaçla ilgili bir spam
ile ilgili daha fazla örnek bulun. Ve bu, öğrenme algoritması performansınızı, her türden e-postadan daha fazla veri eklemeye
çalışmaktan çok daha fazla artırabilir.
ses eklemek için arka plan gürültüsü veya kötü cep telefonu bağlantısı, burada test setinde beklediğinizi temsil ediyorsa, bu,
ses verilerinizde veri artırmayı gerçekleştirmenin yararlı yolları olacaktır. Aksine, verilere tamamen rastgele anlamsız gürültüde
genellikle o kadar yardımcı olmaz.
daha fazla veri toplamaktan herhangi bir şey olabilir. Eğer hata analizi bunu yapmanızı söylediyse. Daha fazla görüntü veya daha
fazla ses oluşturmak için veri büyütmeyi kullanmak veya sadece daha fazla eğitim örneği oluşturmak için veri sentezini kullanmak.
Ve bazen verilere odaklanmak, öğrenme algoritmanızın performansını iyileştirmesine yardımcı olmanın etkili bir yolu olabilir.

## Transfer learning: using data from a different task
Çok fazla veriye sahip olmadığınız bir uygulama için, transfer öğrenimi, uygulamanıza yardımcı olması için farklı bir görevdeki
verileri kullanmanıza izin veren harika bir tekniktir.
büyük bir eğitim setiniz varsa transfer öğrenme biraz daha iyi çalışabilir.
Transfer öğrenimi ile ilgili güzel bir şey de, belki de denetimli ön eğitimi gerçekleştiren kişi olmanıza gerek olmamasıdır.
Birçok sinir ağı için, zaten büyük bir görüntü üzerinde bir sinir ağını eğitmiş ve internette herkesin indirip kullanması için
ücretsiz lisanslı eğitimli bir sinir ağları yayınlamış olan araştırmacılar olacaktır.
Bunun anlamı, ilk adımı kendiniz gerçekleştirmek yerine, bir başkasının haftalarca eğitim almış olabileceği sinir ağını
indirebilir ve ardından çıktı katmanını kendi çıktı katmanınızla değiştirebilir ve ince ayar yapmak için Seçenek 1 veya
Seçenek 2'yi gerçekleştirebilirsiniz.
Adım 1, uygulamanızla aynı giriş tipine sahip büyük bir veri kümesinde önceden eğitilmiş parametrelere sahip sinir ağını
indirmektir. Bu giriş türü resimler, ses, metinler veya başka bir şey olabilir ya da sinir ağını indirmek istemiyorsanız,
belki kendinizinkini eğitebilirsiniz. Ancak pratikte, örneğin görüntüleri kullanıyorsanız, başka birinin önceden eğitilmiş
sinir ağını indirmek çok daha yaygındır. Ardından ağı kendi verilerinize göre daha fazla eğitin veya ince ayar yapın.
Büyük veri kümesi üzerinde önceden eğitilmiş bir sinir ağı elde edebilirseniz, diyelim ki bir milyon görüntü, o zaman
sinir ağına kendi başınıza ince ayar yapmak için bazen çok daha küçük bir veri kümesi, belki bin görüntü, belki daha da küçük
kullanabileceğinizi buldum. veri ve oldukça iyi sonuçlar elde edin.
GPT-3'ü, BERT'leri veya ImageNet'i duymadıysanız, duymuş olsanız da bunun için endişelenmeyin. Bunlar, makine öğrenimi
literatüründe ön eğitimin başarılı uygulamalarıdır.
Transfer öğrenimini gerçekleştirmenin iki olası yolu nedir?
Çıktı katmanları ve önceki katmanlar da dahil olmak üzere modelin tüm parametrelerini eğitmeyi seçebilirsiniz.
Yalnızca çıktı katmanlarının parametrelerini eğitmeyi seçebilir ve modelin diğer parametrelerini sabit bırakabilirsiniz.


## Full cycle of a machine learning project
makine öğrenimi sistemi oluştururken düşünülmesi ve planlanması gereken adımlar nelerdir?
MLOps adı verilen büyüyen bir alan var. Bu, Makine Öğrenimi İşlemleri anlamına gelir. Bu, makine öğrenimi sistemlerinin
sistematik olarak nasıl oluşturulacağı ve dağıtılacağı ve sürdürüleceği pratiğini ifade eder. Makine öğrenimi modelinizin güvenilir
olduğundan, iyi ölçeklendiğinden, iyi yasalara sahip olduğundan, izlendiğinden emin olmak için tüm bunları yapmak için ve
ardından, modelin iyi çalışmasını sağlamak için uygun şekilde güncellemeler yapma fırsatınız olur.

## Error metrics for skewed datasets
Çarpık veri kümeleriyle ilgili sorunlar üzerinde çalışırken, öğrenme algoritmanızın ne kadar iyi çalıştığını anlamak için
genellikle sınıflandırma hatası yerine farklı bir hata metriği kullanırız.
bu dört hücreye isim vereceğim. Gerçek sınıf bir ve tahmin edilen sınıf bir olduğunda, buna gerçek pozitif diyeceğiz çünkü
siz pozitif tahmin ettiniz ve bu doğruydu, pozitif bir örnek var. Sağ alttaki bu hücrede, gerçek sınıfın sıfır ve tahmin edilen
sınıfın sıfır olduğu yerde, buna gerçek bir negatif diyeceğiz çünkü siz negatif tahmin ettiniz ve bu doğruydu. Gerçekten olumsuz
bir örnekti. Sağ üstteki bu hücreye yanlış pozitif denir, çünkü algoritma pozitif tahmin eder, ancak yanlıştır. Aslında pozitif
değil, bu yüzden buna yanlış pozitif denir. Algoritma sıfır öngördüğü için bu hücreye yanlış negatif sayısı denir, ancak yanlıştı.

## Trading off precision and recall
Doğruluk (Accuracy) yerine F1 Score değerinin kullanılmasının en temel sebebi eşit dağılmayan veri kümelerinde hatalı bir model
seçimi yapmamaktır. Ayrıca sadece False Negative ya da False Positive değil tüm hata maliyetlerini de içerecek bir ölçme metriğine
ihtiyaç duyulduğu içinde F1 Score bizim için çok önemlidir.

## Decision tree model
## Learning Process
Karar ağacı öğrenmenin ilk adımı, kök düğümde hangi özelliğin kullanılacağına karar vermemizdir.
Bu, karar ağacının en üstündeki ilk düğümdür.
Bir karar ağacını öğrenirken vermemiz gereken ilk karar, hangi özelliği, salonu ve her bir düğümü nasıl
seçeceğimizdir. Bir karar ağacı oluştururken vermeniz gereken ikinci önemli karar, bölmeyi ne zaman
durduracağınıza karar vermektir

## Measuring purity
entropi işlevi, bir dizi verinin safsızlığının bir ölçüsüdür. Sıfırdan başlar, bire çıkar ve sonra numunenizdeki pozitif örneklerin kesrinin bir fonksiyonu olarak sıfıra geri döner. Buna benzeyen başka fonksiyonlar da var, sıfırdan bire gidiyorlar ve sonra geri düşüyorlar.

## Choosing a split: Information Gain
Bir karar ağacı oluştururken, bir düğümde hangi özelliğin bölüneceğine karar verme şeklimiz, hangi özellik seçiminin entropiyi en çok azalttığına bağlı olacaktır. Entropiyi azaltır veya safsızlığı azaltır veya saflığı en üst düzeye çıkarır. Karar ağacı öğrenmede entropinin azaltılmasına bilgi kazancı denir.

## Putting it together
Bilgi kazanım kriterleri, tek düğümü bölmek için bir özelliğin nasıl seçileceğine karar vermenizi sağlar
Ağacın kök düğümündeki tüm eğitim örnekleriyle başlar ve tüm olası özellikler için bilgi kazancını hesaplar ve
en yüksek bilgi kazancını veren bölünecek özelliği seçer. Bu özelliği seçtikten sonra, veri kümesini seçilen özelliğe
göre iki alt kümeye ayıracak ve ağacın sol ve sağ dallarını oluşturacak ve bu özelliğin değerine göre eğitim örneklerini
sol veya sağ dala göndereceksiniz.
Bu, kök düğümde bir bölme yapmanızı sağlar. Bundan sonra, ağacın sol dalında, sağ dalında vb. bölme işlemini tekrarlamaya
devam edeceksiniz. Durdurma kriterleri karşılanana kadar bunu yapmaya devam edin. Durdurma kriterinin olabileceği durumlarda,
bir düğüm yüzde 100 tek bir tümce olduğunda, birisi entropiye sıfıra ulaştıysa veya bir düğümü daha fazla bölmek ağacın
belirlediğiniz maksimum derinliği aşmasına neden olacaksa veya ek bir bölünme eşikten daha azsa veya bir düğümdeki örnek sayısı
bir eşiğin altındaysa. Bu kriterlerden biri veya birkaçı olabilecek, seçtiğiniz durdurma kriteri karşılanana kadar bölme
işlemini tekrarlamaya devam edeceksiniz.
Doğru alt ağacı oluşturma yöntemimiz, yine beş örnekten oluşan bir alt küme üzerinde bir karar ağacı oluşturmaktı.
Bilgisayar biliminde bu, özyinelemeli bir algoritma örneğidir. Bunun anlamı, kökte bir karar ağacı oluşturmanın yolu,
sol ve sağ alt dallarda başka daha küçük karar ağaçları oluşturmaktır. Bilgisayar biliminde özyineleme, kendini çağıran
kod yazmak anlamına gelir. Bunun bir karar ağacı oluştururken ortaya çıkma şekli, daha küçük alt karar ağaçları oluşturarak
ve ardından hepsini bir araya getirerek genel karar ağacını oluşturmanızdır.

## Continuous valued features

